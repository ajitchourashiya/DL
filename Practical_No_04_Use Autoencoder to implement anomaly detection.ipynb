{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6c10b093",
   "metadata": {},
   "source": [
    "# Use Autoencoder to implement anomaly detection. Build the model by using: \n",
    "a. Import required libraries \n",
    "b. Upload / access the dataset \n",
    "c. Encoder converts it into latent representation \n",
    "d. Decoder networks convert it back to the original input \n",
    "e. Compile the models with Optimizer, Loss, and Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7195c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\scipy\\__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.0\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "# This is the size of our encoded representations\n",
    "encoding_dim = 32  # 32 floats -> compression of factor 24.5, assuming the input is 784 floats\n",
    "# This is our input image\n",
    "input_img = keras.Input(shape=(784,))\n",
    "# \"encoded\" is the encoded representation of the input\n",
    "encoded = layers.Dense(encoding_dim, activation='relu')(input_img)\n",
    "# \"decoded\" is the lossy reconstruction of the input\n",
    "decoded = layers.Dense(784, activation='sigmoid')(encoded)\n",
    "# This model maps an input to its reconstruction\n",
    "autoencoder = keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702402fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's also create a separate encoder model:\n",
    "# This model maps an input to its encoded representation\n",
    "encoder = keras.Model(input_img, encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6396bb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#As well as the decoder model:\n",
    "\n",
    "# This is our encoded (32-dimensional) input\n",
    "encoded_input = keras.Input(shape=(encoding_dim,))\n",
    "# Retrieve the last layer of the autoencoder model\n",
    "decoder_layer = autoencoder.layers[-1]\n",
    "# Create the decoder model\n",
    "decoder = keras.Model(encoded_input, decoder_layer(encoded_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f49e5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now let's train our autoencoder to reconstruct MNIST digits.\n",
    "#z`First, we'll configure our model to use a per-pixel binary crossentropy loss, and the Adam optimizer:\n",
    "autoencoder.compile(optimizer='adam', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d64501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's prepare our input data. We're using MNIST digits, and we're discarding the labels (since we're only interested in encoding/decoding the input images)\n",
    "from keras.datasets import mnist\n",
    "\n",
    "import numpy as np\n",
    "(x_train, _), (x_test, _) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8faed8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784)\n",
      "(10000, 784)\n"
     ]
    }
   ],
   "source": [
    "#We will normalize all values between 0 and 1 and we will flatten the 28x28 images into vectors of size 784.\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
    "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29764df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "235/235 [==============================] - 13s 35ms/step - loss: 0.2753 - val_loss: 0.1878\n",
      "Epoch 2/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.1704 - val_loss: 0.1536\n",
      "Epoch 3/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1445 - val_loss: 0.1341\n",
      "Epoch 4/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1289 - val_loss: 0.1218\n",
      "Epoch 5/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1184 - val_loss: 0.1131\n",
      "Epoch 6/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.1110 - val_loss: 0.1069\n",
      "Epoch 7/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.1057 - val_loss: 0.1024\n",
      "Epoch 8/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.1019 - val_loss: 0.0991\n",
      "Epoch 9/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0992 - val_loss: 0.0969\n",
      "Epoch 10/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0974 - val_loss: 0.0955\n",
      "Epoch 11/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0962 - val_loss: 0.0944\n",
      "Epoch 12/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0954 - val_loss: 0.0940\n",
      "Epoch 13/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0948 - val_loss: 0.0933\n",
      "Epoch 14/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0944 - val_loss: 0.0930\n",
      "Epoch 15/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.0942 - val_loss: 0.0928\n",
      "Epoch 16/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0939 - val_loss: 0.0926\n",
      "Epoch 17/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0938 - val_loss: 0.0924\n",
      "Epoch 18/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0936 - val_loss: 0.0923\n",
      "Epoch 19/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0935 - val_loss: 0.0922\n",
      "Epoch 20/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0934 - val_loss: 0.0922\n",
      "Epoch 21/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0933 - val_loss: 0.0920\n",
      "Epoch 22/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0933 - val_loss: 0.0921\n",
      "Epoch 23/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0932 - val_loss: 0.0921\n",
      "Epoch 24/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0932 - val_loss: 0.0920\n",
      "Epoch 25/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0931 - val_loss: 0.0921\n",
      "Epoch 26/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.0931 - val_loss: 0.0919\n",
      "Epoch 27/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 28/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0930 - val_loss: 0.0919\n",
      "Epoch 29/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.0930 - val_loss: 0.0918\n",
      "Epoch 30/50\n",
      "235/235 [==============================] - 7s 28ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 31/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 32/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 33/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0929 - val_loss: 0.0918\n",
      "Epoch 34/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0929 - val_loss: 0.0917\n",
      "Epoch 35/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 36/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0928 - val_loss: 0.0918\n",
      "Epoch 37/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 38/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 39/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0928 - val_loss: 0.0917\n",
      "Epoch 40/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.0928 - val_loss: 0.0916\n",
      "Epoch 41/50\n",
      "235/235 [==============================] - 6s 27ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 42/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 43/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 44/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 45/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 46/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0927 - val_loss: 0.0917\n",
      "Epoch 47/50\n",
      "235/235 [==============================] - 6s 26ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 48/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0927 - val_loss: 0.0916\n",
      "Epoch 49/50\n",
      "235/235 [==============================] - 6s 25ms/step - loss: 0.0927 - val_loss: 0.0915\n",
      "Epoch 50/50\n",
      "235/235 [==============================] - 6s 24ms/step - loss: 0.0926 - val_loss: 0.0916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x23b6655a340>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Now let's train our autoencoder for 50 epochs:\n",
    "autoencoder.fit(x_train, x_train,\n",
    "                epochs=50,\n",
    "                batch_size=256,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4982872",
   "metadata": {},
   "outputs": [],
   "source": [
    "After 50 epochs, the autoencoder seems to reach a stable train/validation loss value of about 0.09. We can try to visualize the reconstructed inputs and the encoded representations. We will use Matplotlib.\n",
    "# Encode and decode some digits\n",
    "# Note that we take them from the *test* set\n",
    "encoded_imgs = encoder.predict(x_test)\n",
    "decoded_imgs = decoder.predict(encoded_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c2293e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "n = 10  # How many digits we will display\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # Display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(x_test[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    # Display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
